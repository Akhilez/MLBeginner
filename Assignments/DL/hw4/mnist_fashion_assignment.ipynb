{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Assignment 4\n",
    "    Akhil Devarashetti\n",
    "    M13471127\n",
    "    01/29/2020\n",
    "\n",
    "### Question:\n",
    "DL2.py learns a two-layer classifier for the MNIST data as independent pixels.  Run this program to see what prediction accuracy one can get. \n",
    "\n",
    "Replace MNIST with FashionMNIST and run it.\n",
    "\n",
    "Submit your code and screen shots of both executions with comments on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs, num_outputs, num_hiddens = 784, 10, 256\n",
    "batch_size_train = 256\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./data/FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "111.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./data/FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data/FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "159.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.FashionMNIST('./data/', train=True, download=True,\n",
    "                               transform=torchvision.transforms.ToTensor()),\n",
    "    batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.FashionMNIST('./data/', train=False, download=True,\n",
    "                               transform=torchvision.transforms.ToTensor()))\n",
    "test_size = 10000  # may be derived from test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = nn.Sequential(\n",
    "    nn.Linear(num_inputs, num_hiddens),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(num_hiddens, num_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0 0 0.5658122301101685\n",
      "train 0 200 0.5315642356872559\n",
      "test 0 7971 among 10000 correctly classified\n",
      "train 1 0 0.5220981240272522\n",
      "train 1 200 0.590034544467926\n",
      "test 1 7984 among 10000 correctly classified\n",
      "train 2 0 0.6195399165153503\n",
      "train 2 200 0.5191501379013062\n",
      "test 2 8035 among 10000 correctly classified\n",
      "train 3 0 0.5419352054595947\n",
      "train 3 200 0.46312934160232544\n",
      "test 3 8084 among 10000 correctly classified\n",
      "train 4 0 0.5460030436515808\n",
      "train 4 200 0.5966782569885254\n",
      "test 4 8088 among 10000 correctly classified\n",
      "train 5 0 0.5187015533447266\n",
      "train 5 200 0.5155038833618164\n",
      "test 5 8117 among 10000 correctly classified\n",
      "train 6 0 0.4586859345436096\n",
      "train 6 200 0.5226384997367859\n",
      "test 6 8148 among 10000 correctly classified\n",
      "train 7 0 0.5079923272132874\n",
      "train 7 200 0.41665884852409363\n",
      "test 7 8181 among 10000 correctly classified\n",
      "train 8 0 0.47475242614746094\n",
      "train 8 200 0.5014234185218811\n",
      "test 8 8200 among 10000 correctly classified\n",
      "train 9 0 0.4308411180973053\n",
      "train 9 200 0.5402283072471619\n",
      "test 9 8199 among 10000 correctly classified\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model2.parameters(), 1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "for epoch in range(n_epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.reshape(-1, num_inputs)\n",
    "        p = model2(data)\n",
    "        train_loss = loss_fn(p, target)\n",
    "        if batch_idx % 200 == 0:\n",
    "            print('train', epoch, batch_idx, float(train_loss))\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "    m = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data = data.reshape(-1, num_inputs)\n",
    "        if int(torch.argmax(model2(data))) == int(target[0]):\n",
    "            m = m + 1\n",
    "    print(\"test\", epoch, m, \"among\", test_size, \"correctly classified\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The accuracy of the Fashion MNIST dataset on the same model is 81.99%\n",
    "    Akhil Devarashetti\n",
    "    M13471127\n",
    "    01/29/2020"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
