{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Deep Learning Assignment 5\n",
    "    Akhil Devarashetti\n",
    "    M13471127\n",
    "    01/29/2020\n",
    "    \n",
    "### This is the output of the original D11.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size_train = 256\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST\\raw\\train-images-idx3-ubyte.gz to ./data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data/MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('./data/', train=True, download=True,\n",
    "                               transform=torchvision.transforms.ToTensor()),\n",
    "    batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('./data/', train=False, download=True,\n",
    "                               transform=torchvision.transforms.ToTensor()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_size = len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model3 = Net()\n",
    "optimizer = optim.SGD(model3.parameters(), 1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0 0 2.319638729095459\n",
      "train 0 100 2.2899749279022217\n",
      "train 0 200 2.2752559185028076\n",
      "test 0 1563 among 10000 correctly classified\n",
      "train 1 0 2.2754740715026855\n",
      "train 1 100 2.25004243850708\n",
      "train 1 200 2.2112553119659424\n",
      "test 1 2651 among 10000 correctly classified\n",
      "train 2 0 2.178285598754883\n",
      "train 2 100 2.0005710124969482\n",
      "train 2 200 1.631392478942871\n",
      "test 2 5078 among 10000 correctly classified\n",
      "train 3 0 1.576619029045105\n",
      "train 3 100 1.330174446105957\n",
      "train 3 200 1.017940878868103\n",
      "test 3 6800 among 10000 correctly classified\n",
      "train 4 0 0.997166097164154\n",
      "train 4 100 0.9177532196044922\n",
      "train 4 200 0.8289182782173157\n",
      "test 4 7496 among 10000 correctly classified\n",
      "train 5 0 0.7848453521728516\n",
      "train 5 100 0.7827498316764832\n",
      "train 5 200 0.7104468941688538\n",
      "test 5 7828 among 10000 correctly classified\n",
      "train 6 0 0.6206013560295105\n",
      "train 6 100 0.6334372162818909\n",
      "train 6 200 0.5051741600036621\n",
      "test 6 8003 among 10000 correctly classified\n",
      "train 7 0 0.5524560809135437\n",
      "train 7 100 0.5070249438285828\n",
      "train 7 200 0.7495488524436951\n",
      "test 7 8223 among 10000 correctly classified\n",
      "train 8 0 0.6291106939315796\n",
      "train 8 100 0.8037195801734924\n",
      "train 8 200 0.5419430732727051\n",
      "test 8 8325 among 10000 correctly classified\n",
      "train 9 0 0.5709067583084106\n",
      "train 9 100 0.6049865484237671\n",
      "train 9 200 0.5164299011230469\n",
      "test 9 8465 among 10000 correctly classified\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        p = model3(data)\n",
    "        train_loss = loss_fn(p, target)\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('train', epoch, batch_idx, float(train_loss))\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "    m = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if int(torch.argmax(model3(data))) == int(target[0]):\n",
    "            m = m + 1\n",
    "    print(\"test\", epoch, m, \"among\", test_size, \"correctly classified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "### The accuracy is 84.65%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
