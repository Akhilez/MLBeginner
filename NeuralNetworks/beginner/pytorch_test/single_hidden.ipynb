{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt('data/iris.txt')\n",
    "np.random.shuffle(data)\n",
    "\n",
    "x = torch.tensor(data[:, :4], dtype=torch.float32)\n",
    "y = torch.tensor(data[:, -1], dtype=torch.float32)\n",
    "y = y.reshape(len(y), 1)\n",
    "\n",
    "split_index = int(len(data) * 0.8) \n",
    "\n",
    "x_train = x[:split_index]\n",
    "x_test = x[split_index:]\n",
    "\n",
    "y_train = y[:split_index]\n",
    "y_test = y[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "X_train shape: torch.Size([120, 4])\n",
      "X_test shape: torch.Size([30, 4])\n",
      "Y_train shape: torch.Size([120, 1])\n",
      "Y_test shape: torch.Size([30, 1])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(f\"X_train shape: {x_train.shape}\")\n",
    "print(f\"X_test shape: {x_test.shape}\")\n",
    "print(f\"Y_train shape: {y_train.shape}\")\n",
    "print(f\"Y_test shape: {y_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "weights1 = torch.rand((4, 5), requires_grad=True)\n",
    "biases1 = torch.rand(5, requires_grad=True)\n",
    "\n",
    "weights2 = torch.rand((5, 1), requires_grad=True)\n",
    "biases2 = torch.rand(1, requires_grad=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "batch_size = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch = 0 | Loss = tensor([82.1649], grad_fn=<AddBackward0>)\n",
      "Epoch = 1 | Loss = tensor([82.1428], grad_fn=<AddBackward0>)\n",
      "Epoch = 2 | Loss = tensor([82.1262], grad_fn=<AddBackward0>)\n",
      "Epoch = 3 | Loss = tensor([82.1133], grad_fn=<AddBackward0>)\n",
      "Epoch = 4 | Loss = tensor([82.1030], grad_fn=<AddBackward0>)\n",
      "Epoch = 5 | Loss = tensor([82.0945], grad_fn=<AddBackward0>)\n",
      "Epoch = 6 | Loss = tensor([82.0873], grad_fn=<AddBackward0>)\n",
      "Epoch = 7 | Loss = tensor([82.0813], grad_fn=<AddBackward0>)\n",
      "Epoch = 8 | Loss = tensor([82.0761], grad_fn=<AddBackward0>)\n",
      "Epoch = 9 | Loss = tensor([82.0715], grad_fn=<AddBackward0>)\n",
      "Epoch = 10 | Loss = tensor([82.0675], grad_fn=<AddBackward0>)\n",
      "Epoch = 11 | Loss = tensor([82.0640], grad_fn=<AddBackward0>)\n",
      "Epoch = 12 | Loss = tensor([82.0608], grad_fn=<AddBackward0>)\n",
      "Epoch = 13 | Loss = tensor([82.0579], grad_fn=<AddBackward0>)\n",
      "Epoch = 14 | Loss = tensor([82.0554], grad_fn=<AddBackward0>)\n",
      "Epoch = 15 | Loss = tensor([82.0530], grad_fn=<AddBackward0>)\n",
      "Epoch = 16 | Loss = tensor([82.0509], grad_fn=<AddBackward0>)\n",
      "Epoch = 17 | Loss = tensor([82.0489], grad_fn=<AddBackward0>)\n",
      "Epoch = 18 | Loss = tensor([82.0471], grad_fn=<AddBackward0>)\n",
      "Epoch = 19 | Loss = tensor([82.0454], grad_fn=<AddBackward0>)\n",
      "Epoch = 20 | Loss = tensor([82.0439], grad_fn=<AddBackward0>)\n",
      "Epoch = 21 | Loss = tensor([82.0424], grad_fn=<AddBackward0>)\n",
      "Epoch = 22 | Loss = tensor([82.0411], grad_fn=<AddBackward0>)\n",
      "Epoch = 23 | Loss = tensor([82.0398], grad_fn=<AddBackward0>)\n",
      "Epoch = 24 | Loss = tensor([82.0387], grad_fn=<AddBackward0>)\n",
      "Epoch = 25 | Loss = tensor([82.0376], grad_fn=<AddBackward0>)\n",
      "Epoch = 26 | Loss = tensor([82.0365], grad_fn=<AddBackward0>)\n",
      "Epoch = 27 | Loss = tensor([82.0355], grad_fn=<AddBackward0>)\n",
      "Epoch = 28 | Loss = tensor([82.0346], grad_fn=<AddBackward0>)\n",
      "Epoch = 29 | Loss = tensor([82.0337], grad_fn=<AddBackward0>)\n",
      "Epoch = 30 | Loss = tensor([82.0329], grad_fn=<AddBackward0>)\n",
      "Epoch = 31 | Loss = tensor([82.0321], grad_fn=<AddBackward0>)\n",
      "Epoch = 32 | Loss = tensor([82.0314], grad_fn=<AddBackward0>)\n",
      "Epoch = 33 | Loss = tensor([82.0307], grad_fn=<AddBackward0>)\n",
      "Epoch = 34 | Loss = tensor([82.0300], grad_fn=<AddBackward0>)\n",
      "Epoch = 35 | Loss = tensor([82.0293], grad_fn=<AddBackward0>)\n",
      "Epoch = 36 | Loss = tensor([82.0287], grad_fn=<AddBackward0>)\n",
      "Epoch = 37 | Loss = tensor([82.0281], grad_fn=<AddBackward0>)\n",
      "Epoch = 38 | Loss = tensor([82.0276], grad_fn=<AddBackward0>)\n",
      "Epoch = 39 | Loss = tensor([82.0270], grad_fn=<AddBackward0>)\n",
      "Epoch = 40 | Loss = tensor([82.0265], grad_fn=<AddBackward0>)\n",
      "Epoch = 41 | Loss = tensor([82.0260], grad_fn=<AddBackward0>)\n",
      "Epoch = 42 | Loss = tensor([82.0255], grad_fn=<AddBackward0>)\n",
      "Epoch = 43 | Loss = tensor([82.0250], grad_fn=<AddBackward0>)\n",
      "Epoch = 44 | Loss = tensor([82.0246], grad_fn=<AddBackward0>)\n",
      "Epoch = 45 | Loss = tensor([82.0242], grad_fn=<AddBackward0>)\n",
      "Epoch = 46 | Loss = tensor([82.0238], grad_fn=<AddBackward0>)\n",
      "Epoch = 47 | Loss = tensor([82.0234], grad_fn=<AddBackward0>)\n",
      "Epoch = 48 | Loss = tensor([82.0230], grad_fn=<AddBackward0>)\n",
      "Epoch = 49 | Loss = tensor([82.0226], grad_fn=<AddBackward0>)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    total_loss = 0\n",
    "    for batch_i in range(0, len(x_train), batch_size):\n",
    "        x_batch = x_train[batch_i:batch_i+batch_size]\n",
    "        y_batch = y_train[batch_i:batch_i+batch_size]\n",
    "\n",
    "        h = torch.sigmoid(torch.mm(x_batch, weights1) + biases1)\n",
    "        y_hat = torch.sigmoid(torch.mm(h, weights2) + biases2)\n",
    "        \n",
    "        loss = sum((y_hat - y_batch) ** 2)\n",
    "        \n",
    "        loss.backward()\n",
    "        total_loss += loss\n",
    "        total_loss.detach()\n",
    "        \n",
    "        weights2 = weights2 - learning_rate * weights2.grad\n",
    "        biases2 = biases2 - learning_rate * biases2.grad\n",
    "        weights1 = weights1 - learning_rate * weights1.grad\n",
    "        biases1 = biases1 - learning_rate * biases1.grad\n",
    "        \n",
    "        weights1 = weights1.detach().requires_grad_()\n",
    "        biases1 = biases1.detach().requires_grad_()\n",
    "        weights2 = weights2.detach().requires_grad_()\n",
    "        biases2 = biases2.detach().requires_grad_()\n",
    "    \n",
    "    print(f\"Epoch = {epoch} | Loss = {total_loss}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}